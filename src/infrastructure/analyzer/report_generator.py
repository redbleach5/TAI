"""Report Generator - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞.

–°–æ–∑–¥–∞—ë—Ç Markdown –æ—Ç—á—ë—Ç—ã —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

Production-ready with:
- Markdown special character escaping
- Null/empty safety checks
"""

import re
from datetime import datetime
from pathlib import Path

from src.infrastructure.analyzer.models import ProjectAnalysis


def escape_markdown(text: str | None) -> str:
    """Escape markdown special characters in text.

    Escapes: | ` * _ [ ] ( ) # + - . !
    """
    if not text:
        return ""
    # Escape pipe (most important for tables)
    text = text.replace("|", "\\|")
    # Escape backticks
    text = text.replace("`", "\\`")
    # Escape asterisks and underscores (but not when used for emphasis)
    # Only escape at word boundaries to avoid breaking formatting
    text = re.sub(r"(\*+)(?=\S)", r"\\\1", text)
    text = re.sub(r"(?<=\S)(\*+)", r"\\\1", text)
    return text


def safe_str(value: str | None, default: str = "") -> str:
    """Return value if not None/empty, else default."""
    return value if value else default


class ReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á—ë—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞."""

    def generate_markdown(self, analysis: ProjectAnalysis | None) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown –æ—Ç—á—ë—Ç.

        Args:
            analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞

        Returns:
            Markdown —Å—Ç—Ä–æ–∫–∞ —Å –æ—Ç—á—ë—Ç–æ–º

        """
        if analysis is None:
            return "# –û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞\n\n**–û—à–∏–±–∫–∞:** –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        sections = [
            self._header(analysis),
            self._executive_summary(analysis),
            self._scores_section(analysis),
            self._statistics_section(analysis),
            self._languages_section(analysis),
            self._security_section(analysis),
            self._quality_section(analysis),
            self._architecture_section(analysis),
            self._recommendations_section(analysis),
            self._top_files_section(analysis),
            self._footer(analysis),
        ]

        # Filter out empty sections
        sections = [s for s in sections if s and s.strip()]

        return "\n\n".join(sections)

    def _header(self, analysis: ProjectAnalysis) -> str:
        """–ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á—ë—Ç–∞."""
        project_name = safe_str(analysis.project_name, "Unknown")
        project_path = safe_str(analysis.project_path, "Unknown")
        analyzed_at = safe_str(analysis.analyzed_at, datetime.now().isoformat())

        return f"""# üìä –û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞

 **–ü—Ä–æ–µ–∫—Ç:** `{escape_markdown(project_name)}`
 **–ü—É—Ç—å:** `{escape_markdown(project_path)}`
**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {analyzed_at}

---"""

    def _executive_summary(self, analysis: ProjectAnalysis) -> str:
        """Build executive summary section."""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É
        security_score = analysis.security_score if analysis.security_score is not None else 0
        quality_score = analysis.quality_score if analysis.quality_score is not None else 0
        overall = (security_score + quality_score) // 2

        if overall >= 80:
            status = "üü¢ **–ó–î–û–†–û–í–´–ô**"
            emoji = "‚úÖ"
        elif overall >= 60:
            status = "üü° **–¢–†–ï–ë–£–ï–¢ –í–ù–ò–ú–ê–ù–ò–Ø**"
            emoji = "‚ö†Ô∏è"
        else:
            status = "üî¥ **–ö–†–ò–¢–ò–ß–ù–û**"
            emoji = "‚ùå"

        strengths = analysis.strengths if analysis.strengths else []
        weaknesses = analysis.weaknesses if analysis.weaknesses else []

        strengths_str = "\n".join(f"- {escape_markdown(s)}" for s in strengths[:5] if s) or "- –ù–µ –≤—ã—è–≤–ª–µ–Ω–æ"
        weaknesses_str = "\n".join(f"- {escape_markdown(w)}" for w in weaknesses[:5] if w) or "- –ù–µ –≤—ã—è–≤–ª–µ–Ω–æ"

        return f"""## üìã –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ

### –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å: {status}

| –ú–µ—Ç—Ä–∏–∫–∞ | –û—Ü–µ–Ω–∫–∞ | –°—Ç–∞—Ç—É—Å |
|---------|--------|--------|
| –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å | {security_score}/100 | {self._score_emoji(security_score)} |
| –ö–∞—á–µ—Å—Ç–≤–æ | {quality_score}/100 | {self._score_emoji(quality_score)} |
| **–ò—Ç–æ–≥–æ** | **{overall}/100** | {emoji} |

### –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
{strengths_str}

### –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
{weaknesses_str}"""

    def _score_emoji(self, score: int) -> str:
        """–≠–º–æ–¥–∑–∏ –¥–ª—è score."""
        if score >= 80:
            return "üü¢ –•–æ—Ä–æ—à–æ"
        elif score >= 60:
            return "üü° –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
        elif score >= 40:
            return "üü† –ü–ª–æ—Ö–æ"
        else:
            return "üî¥ –ö—Ä–∏—Ç–∏—á–Ω–æ"

    def _scores_section(self, analysis: ProjectAnalysis) -> str:
        """–°–µ–∫—Ü–∏—è —Å–æ scores (ASCII –¥–∏–∞–≥—Ä–∞–º–º—ã)."""
        security_bar = self._progress_bar(analysis.security_score)
        quality_bar = self._progress_bar(analysis.quality_score)

        return f"""## üìà –û—Ü–µ–Ω–∫–∏

### –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
```
{security_bar} {analysis.security_score}%
```

### –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞
```
{quality_bar} {analysis.quality_score}%
```"""

    def _progress_bar(self, score: int, width: int = 30) -> str:
        """–°–æ–∑–¥–∞—ë—Ç ASCII progress bar."""
        filled = int(width * score / 100)
        empty = width - filled
        return f"[{'‚ñà' * filled}{'‚ñë' * empty}]"

    def _statistics_section(self, analysis: ProjectAnalysis) -> str:
        """–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞."""
        avg_file_size = analysis.total_lines // max(1, analysis.total_files)
        comment_ratio = 0
        if analysis.total_code_lines > 0:
            total_comments = sum(f.lines_comment for f in analysis.file_metrics)
            comment_ratio = round(total_comments / analysis.total_code_lines * 100, 1)

        return f"""## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ | {analysis.total_files} |
| –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ | {analysis.total_lines:,} |
| –°—Ç—Ä–æ–∫ –∫–æ–¥–∞ | {analysis.total_code_lines:,} |
| –°—Ä. —Å—Ç—Ä–æ–∫/—Ñ–∞–π–ª | {avg_file_size} |
| –î–æ–ª—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ | {comment_ratio}% |
| –Ø–∑—ã–∫–æ–≤ | {len(analysis.languages)} |
| –ü—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ | {len(analysis.security_issues)} |
| Code smells | {len(analysis.code_smells)} |"""

    def _languages_section(self, analysis: ProjectAnalysis) -> str:
        """–°–µ–∫—Ü–∏—è —è–∑—ã–∫–æ–≤."""
        if not analysis.languages:
            return ""

        total = sum(analysis.languages.values())
        if total == 0:
            return ""

        rows = []

        for lang, count in sorted(analysis.languages.items(), key=lambda x: -x[1]):
            if not lang:
                continue
            pct = round(count / total * 100, 1)
            bar = "‚ñà" * int(pct / 5)
            rows.append(f"| {escape_markdown(lang)} | {count} | {pct}% | {bar} |")

        if not rows:
            return ""

        return f"""## üåê –Ø–∑—ã–∫–∏

| –Ø–∑—ã–∫ | –§–∞–π–ª–æ–≤ | % | –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ |
|------|--------|---|---------------|
{chr(10).join(rows)}"""

    def _security_section(self, analysis: ProjectAnalysis) -> str:
        """–°–µ–∫—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."""
        if not analysis.security_issues:
            return """## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

‚úÖ **–ü—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!**"""

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ severity
        by_severity = {"critical": [], "high": [], "medium": [], "low": []}
        for issue in analysis.security_issues:
            by_severity[issue.severity].append(issue)

        sections = ["## üîí Security\n"]

        severity_emoji = {
            "critical": "üî¥ –ö–†–ò–¢–ò–ß–ù–û",
            "high": "üü† –í–´–°–û–ö–ò–ô",
            "medium": "üü° –°–†–ï–î–ù–ò–ô",
            "low": "‚ö™ –ù–ò–ó–ö–ò–ô",
        }

        for severity in ["critical", "high", "medium", "low"]:
            issues = by_severity[severity]
            if issues:
                sections.append(f"\n### {severity_emoji[severity]} ({len(issues)})\n")
                sections.append("| –§–∞–π–ª | –°—Ç—Ä–æ–∫–∞ | –ü—Ä–æ–±–ª–µ–º–∞ | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |")
                sections.append("|------|--------|----------|--------------|")
                for issue in issues[:10]:  # Limit to 10 per severity
                    file_path = escape_markdown(safe_str(issue.file, "unknown"))
                    issue_text = escape_markdown(safe_str(issue.issue, ""))
                    rec_text = escape_markdown(safe_str(issue.recommendation, ""))
                    sections.append(f"| `{file_path}` | {issue.line} | {issue_text} | {rec_text} |")

        return "\n".join(sections)

    def _quality_section(self, analysis: ProjectAnalysis) -> str:
        """–°–µ–∫—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞."""
        if not analysis.code_smells:
            return """## üéØ –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞

‚úÖ **–°–µ—Ä—å—ë–∑–Ω—ã—Ö code smells –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!**"""

        smells_list = "\n".join(f"- `{escape_markdown(smell)}`" for smell in analysis.code_smells[:15] if smell)

        if not smells_list:
            return """## üéØ –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞

‚úÖ **–°–µ—Ä—å—ë–∑–Ω—ã—Ö code smells –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!**"""

        return f"""## üéØ –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞

### Code smells ({len(analysis.code_smells)})

{smells_list}"""

    def _architecture_section(self, analysis: ProjectAnalysis) -> str:
        """–°–µ–∫—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã."""
        arch = analysis.architecture
        if not arch:
            return "## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n\n–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ."

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        layers = ""
        if arch.layers:
            layers = "### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π\n\n```\n"
            for layer, files in sorted(arch.layers.items()):
                # No escaping needed inside code blocks
                safe_layer = safe_str(layer, "unknown")
                file_count = len(files) if files else 0
                layers += f"üìÅ {safe_layer}/ ({file_count} files)\n"
            layers += "```\n"

        # Entry points
        entries = ""
        if arch.entry_points:
            entries = "### –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞\n\n"
            entries += "\n".join(f"- `{escape_markdown(safe_str(e, ''))}`" for e in arch.entry_points if e)
            entries += "\n"

        # Config files
        configs = ""
        if arch.config_files:
            configs = "### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n\n"
            configs += "\n".join(f"- `{escape_markdown(safe_str(c, ''))}`" for c in arch.config_files[:10] if c)
            configs += "\n"

        return f"""## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

{layers}
{entries}
{configs}"""

    def _recommendations_section(self, analysis: ProjectAnalysis) -> str:
        """–°–µ–∫—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."""
        if not analysis.recommendations:
            return """## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

‚úÖ **–ö—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç. –•–æ—Ä–æ—à–∞—è —Ä–∞–±–æ—Ç–∞!**"""

        recs = "\n".join(f"{i + 1}. {escape_markdown(rec)}" for i, rec in enumerate(analysis.recommendations) if rec)

        if not recs:
            return """## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

‚úÖ **–ö—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç. –•–æ—Ä–æ—à–∞—è —Ä–∞–±–æ—Ç–∞!**"""

        return f"""## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

{recs}"""

    def _top_files_section(self, analysis: ProjectAnalysis) -> str:
        """–¢–æ–ø —Ñ–∞–π–ª–æ–≤ –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏."""
        if not analysis.file_metrics:
            return ""

        # Top by lines
        by_lines = sorted(analysis.file_metrics, key=lambda f: -f.lines_code)[:5]
        lines_rows = [
            f"| `{escape_markdown(safe_str(f.path, 'unknown'))}` | {f.lines_code} | {f.functions} | {f.classes} |"
            for f in by_lines
            if f and f.path
        ]

        # Top by complexity (only Python)
        by_complexity = sorted(
            [f for f in analysis.file_metrics if f and f.complexity > 0], key=lambda f: -f.complexity
        )[:5]
        complexity_rows = [
            f"| `{escape_markdown(safe_str(f.path, 'unknown'))}` | {f.complexity} |"
            for f in by_complexity
            if f and f.path
        ]

        lines_content = chr(10).join(lines_rows) if lines_rows else "| –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ | - | - | - |"
        complexity_content = chr(10).join(complexity_rows) if complexity_rows else "| –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ | - |"

        return f"""## üìÅ –¢–æ–ø —Ñ–∞–π–ª–æ–≤

### –ü–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–æ–∫

| –§–∞–π–ª | –°—Ç—Ä–æ–∫ | –§—É–Ω–∫—Ü–∏–π | –ö–ª–∞—Å—Å–æ–≤ |
|------|-------|---------|---------|
{lines_content}

### –ü–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (Python)

| –§–∞–π–ª | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
|------|-----------|
{complexity_content}"""

    def _footer(self, analysis: ProjectAnalysis) -> str:
        """–§—É—Ç–µ—Ä –æ—Ç—á—ë—Ç–∞."""
        return f"""---

 *–û—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω TAi v3 Project Analyzer*
 *{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*"""

    def save_report(self, analysis: ProjectAnalysis, output_path: str | Path) -> Path:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á—ë—Ç –≤ —Ñ–∞–π–ª.

        Args:
            analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        Returns:
            Path –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É

        """
        output = Path(output_path)
        content = self.generate_markdown(analysis)
        output.write_text(content, encoding="utf-8")
        return output
